{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, Conv2D, MaxPooling2D, Input, Cropping2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from utils import utils\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = utils.get_train('data/IMG/', 'data/driving_log.csv')\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2, y_train2 = utils.get_train('data-driver-apo-reverse/IMG/', 'data-driver-apo-reverse/driving_log.csv')\n",
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2), axis=0)\n",
    "y_train = np.concatenate((y_train1, y_train2), axis=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_height, img_width = X_train.shape[1], X_train.shape[2]\n",
    "img_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(p=0.6, input_shape=(160, 320, 3)):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 255. - .5, input_shape=input_shape))\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    # Convolutional \n",
    "    model.add(Conv2D(24, (5, 5), strides=(2,2), activation ='relu'))\n",
    "    model.add(Conv2D(36, (5, 5), strides=(2,2), activation ='relu'))\n",
    "    model.add(Conv2D(48, (5, 5), strides=(2,2), activation ='relu')) \n",
    "    model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "    # Fully-Connection\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(1e-3)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])   \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, y, epochs=10, batch_size=32, modelname='model.h5'):\n",
    "    trX, teX, trY, teY = train_test_split(X, y, test_size=0.2, random_state=seed) \n",
    "    model = create_model(0.6, img_shape)\n",
    "    history = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, validation_data=(teX, teY), shuffle=True)\n",
    "    model.save('models/' + modelname)\n",
    "    print (\"Model saved.\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainCV(X, y, nfolds=5, epochs=10, batch_size=32, model_dir=\"./\"):\n",
    "    # K-Fold cross-validation \n",
    "    kfold = KFold(n_splits=nfolds, shuffle=True, random_state=seed)\n",
    "    # Pre-train\n",
    "    pre_model = create_model(p=0.6, input_shape=img_shape) \n",
    "    pre_model.fit(X, y, batch_size=32, epochs=1, shuffle=True, verbose=1)\n",
    "    pre_model.save_weights(\"pre-trained-model_w.h5\")\n",
    "    # Create directory for models\n",
    "    utils.create_dir(model_dir)\n",
    "    for k, (xi, cvi) in enumerate(kfold.split(X)):\n",
    "        print(\"Fold {} of {}:\".format(k+1, nfolds)) \n",
    "        model = create_model(p=0.6, input_shape=img_shape)\n",
    "        model.load_weights(\"pre-trained-model_w.h5\")\n",
    "        trX, cvX = X[xi], X[cvi] \n",
    "        trY, cvY = y[xi], y[cvi]\n",
    "        # Callbacks\n",
    "        modelname = \"model\" + \"-fold-\" + str(k+1) + \".h5\" \n",
    "        modelckpt = ModelCheckpoint(model_dir+\"/\" + modelname, monitor='val_loss', save_best_only=True)\n",
    "        earlystop = EarlyStopping(monitor='val_acc', patience=2, verbose=0)\n",
    "        callbacks = [earlystop, modelckpt]\n",
    "        # Training\n",
    "        model.fit(trX, trY, \n",
    "                  batch_size=32, \n",
    "                  epochs=epochs, \n",
    "                  shuffle=True, \n",
    "                  verbose=1,\n",
    "                  validation_data=(cvX, cvY), \n",
    "                  callbacks=callbacks)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainCV(X_train, y_train, nfolds=3, epochs=5, batch_size=128, model_dir=\"models/test\")\n",
    "train(X_train, y_train, epochs=5, batch_size=32, modelname=\"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
